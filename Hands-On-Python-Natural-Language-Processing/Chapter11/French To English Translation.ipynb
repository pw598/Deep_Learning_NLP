{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pun7VarqeGL4",
    "outputId": "85999551-fb2b-4a46-84e6-73e37c13243e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import io\n",
    "import numpy as np\n",
    "from unicodedata import normalize\n",
    "import keras, tensorflow\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C92VgDWZeGMA"
   },
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    data = []\n",
    "    with io.open(file, 'r') as file:\n",
    "        for entry in file:\n",
    "            entry = entry.strip()\n",
    "            data.append(entry)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wccatfy6eGMX"
   },
   "outputs": [],
   "source": [
    "data = read_data('dataset/bilingual_pairs.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some basics about our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Never choose a vocation just because the hours are short.\\tNe choisissez jamais une profession juste parce que les heures y sont courtes.',\n",
       " \"No other mountain in the world is so high as Mt. Everest.\\tAucune montagne au monde n'atteint la hauteur du Mont Everest.\",\n",
       " \"No sooner had he met his family than he burst into tears.\\tÀ peine avait-il rencontré sa famille qu'il éclata en sanglots.\",\n",
       " \"Nothing is more disappointing than to lose in the finals.\\tRien n'est plus décevant que de perdre en finale.\",\n",
       " \"Now that he is old, it is your duty to go look after him.\\tÀ présent qu'il est vieux, c'est ton devoir de veiller sur lui.\",\n",
       " \"Now that you've decided to quit your job, you look happy.\\tMaintenant que vous avez décidé de quitter votre emploi, vous avez l'air heureux.\",\n",
       " \"Now that you've decided to quit your job, you look happy.\\tMaintenant que tu as décidé de quitter ton emploi, tu as l'air heureux.\",\n",
       " \"Now that you've decided to quit your job, you look happy.\\tMaintenant que vous avez décidé de quitter votre emploi, vous avez l'air heureuse.\",\n",
       " \"Now that you've decided to quit your job, you look happy.\\tMaintenant que tu as décidé de quitter ton emploi, tu as l'air heureuse.\",\n",
       " 'Please drop in when you happen to be in the neighborhood.\\tVeuillez donc passer quand vous êtes dans le coin !']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[139990:140000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o7v6YuIQqkdC",
    "outputId": "6db8a27d-20b3-4814-9ba3-09dc4e3160ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145437"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mn5AJq_7eGMc"
   },
   "outputs": [],
   "source": [
    "data = data[:140000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting our data into English and French sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5izP_MfWeGMi"
   },
   "outputs": [],
   "source": [
    "def build_english_french_sentences(data):\n",
    "    english_sentences = []\n",
    "    french_sentences = []\n",
    "    for data_point in data:\n",
    "        english_sentences.append(data_point.split(\"\\t\")[0])\n",
    "        french_sentences.append(data_point.split(\"\\t\")[1])\n",
    "    return english_sentences, french_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lU1AA_dkeGMn"
   },
   "outputs": [],
   "source": [
    "english_sentences, french_sentences = build_english_french_sentences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sHtX637EeGMs",
    "outputId": "c10578eb-cd7b-4152-936f-f41128fc7eae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GwE2jPKIeGM1",
    "outputId": "f5d5cfc5-34cc-4e6c-be76-6df28fc6d513"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(french_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QgEQbWyLeGM6"
   },
   "outputs": [],
   "source": [
    "def clean_sentences(sentence):\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    cleaned_sent = normalize('NFD', sentence).encode('ascii', 'ignore')\n",
    "    cleaned_sent = cleaned_sent.decode('UTF-8')\n",
    "    cleaned_sent = cleaned_sent.split()\n",
    "    cleaned_sent = [word.lower() for word in cleaned_sent]\n",
    "    cleaned_sent = [word.translate(table) for word in cleaned_sent]\n",
    "    cleaned_sent = [re_print.sub('', w) for w in cleaned_sent]\n",
    "    cleaned_sent = [word for word in cleaned_sent if word.isalpha()]\n",
    "    return ' '.join(cleaned_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PEeqZNNeGM_"
   },
   "outputs": [],
   "source": [
    "def build_clean_english_french_sentences(english_sentences, french_sentences):\n",
    "    french_sentences_cleaned = []\n",
    "    english_sentences_cleaned = []\n",
    "    for sent in french_sentences:\n",
    "        french_sentences_cleaned.append(clean_sentences(sent))\n",
    "    for sent in english_sentences:\n",
    "        english_sentences_cleaned.append(clean_sentences(sent))\n",
    "    return english_sentences_cleaned, french_sentences_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpg30uqIeGND"
   },
   "outputs": [],
   "source": [
    "english_sentences_cleaned, french_sentences_cleaned = build_clean_english_french_sentences(english_sentences, \n",
    "                                                                                           french_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VPL2FfwweGNJ",
    "outputId": "5ad0f65c-4a1a-4811-f821-f4228d910a33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i think i can fix this'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences_cleaned[40884]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2nokZ3D5eGNP",
    "outputId": "4a0f930e-5ddc-439b-a7a4-222b32e146f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'je pense que je peux arranger ca'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_sentences_cleaned[40884]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our input and target datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ys2VR-NZeGNU"
   },
   "outputs": [],
   "source": [
    "def build_data(english_sentences_cleaned, french_sentences_cleaned):\n",
    "    input_dataset = []\n",
    "    target_dataset = []\n",
    "    input_characters = set()\n",
    "    target_characters = set()\n",
    "    \n",
    "    for french_sentence in french_sentences_cleaned:\n",
    "        input_datapoint = french_sentence\n",
    "        input_dataset.append(input_datapoint)\n",
    "        for char in input_datapoint:\n",
    "            input_characters.add(char)\n",
    "        \n",
    "    for english_sentence in english_sentences_cleaned:\n",
    "        target_datapoint = \"\\t\" + english_sentence + \"\\n\"\n",
    "        target_dataset.append(target_datapoint)\n",
    "        for char in target_datapoint:\n",
    "            target_characters.add(char)\n",
    "            \n",
    "    return input_dataset, target_dataset, sorted(list(input_characters)), sorted(list(target_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DrOsk6f_eGNb"
   },
   "outputs": [],
   "source": [
    "input_dataset, target_dataset, input_characters, target_characters = build_data(english_sentences_cleaned,\n",
    "                                                                                french_sentences_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qo7TiTaOeGNg",
    "outputId": "b00c8f77-966d-422c-d961-5e5325c141a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2ZqARjhWeGNl",
    "outputId": "e1bd2619-e304-45ce-8b5c-11eac2212640"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_ylMPx5neGNp",
    "outputId": "aa645d32-6d8c-4ed5-da3e-743cfea5ec7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(input_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "7CBV9vvieGNv",
    "outputId": "785f5038-97df-4753-fc09-733578dca8eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(target_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining metadata for our data structures and model to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Haj_b9-yeGNz"
   },
   "outputs": [],
   "source": [
    "def build_metadata(input_dataset, target_dataset, input_characters, target_characters):\n",
    "    num_encoder_tokens = len(input_characters)\n",
    "    num_decoder_tokens = len(target_characters)\n",
    "    max_encoder_seq_length = max([len(data_point) for data_point in input_dataset])\n",
    "    max_decoder_seq_length = max([len(data_point) for data_point in target_dataset])\n",
    "\n",
    "    print('Number of data points:', len(input_dataset))\n",
    "    print('Number of unique input tokens:', num_encoder_tokens)\n",
    "    print('Number of unique output tokens:', num_decoder_tokens)\n",
    "    print('Maximum sequence length for inputs:', max_encoder_seq_length)\n",
    "    print('Maximum sequence length for outputs:', max_decoder_seq_length)\n",
    "    \n",
    "    return num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "To-bA7SPeGN3",
    "outputId": "77f4afdd-b488-453c-f6c8-198e99711649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 140000\n",
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 29\n",
      "Maximum sequence length for inputs: 117\n",
      "Maximum sequence length for outputs: 58\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length = build_metadata(input_dataset,\n",
    "                                                                                                        target_dataset,\n",
    "                                                                                                        input_characters,\n",
    "                                                                                                        target_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing mappings for character to index and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgmvQ088eGN7"
   },
   "outputs": [],
   "source": [
    "def build_indices(input_characters, target_characters):\n",
    "    input_char_to_idx = {}\n",
    "    input_idx_to_char = {}\n",
    "    target_char_to_idx = {}\n",
    "    target_idx_to_char = {}\n",
    "    \n",
    "    for i, char in enumerate(input_characters):\n",
    "        input_char_to_idx[char] = i\n",
    "        input_idx_to_char[i] = char\n",
    "    \n",
    "    for i, char in enumerate(target_characters):\n",
    "        target_char_to_idx[char] = i\n",
    "        target_idx_to_char[i] = char\n",
    "    \n",
    "    return input_char_to_idx, input_idx_to_char, target_char_to_idx, target_idx_to_char\n",
    "\n",
    "input_char_to_idx, input_idx_to_char, target_char_to_idx, target_idx_to_char = build_indices(input_characters,\n",
    "                                                                                             target_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building data structures to accommodate our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "PwJ3acmneGN-",
    "outputId": "c9222273-86aa-4b1a-e4b5-8dbef1ac1a89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of encoder input data is :  (140000, 117, 27)\n",
      "Dimensionality of decoder input data is :  (140000, 58, 29)\n",
      "Dimensionality of decoder target data is :  (140000, 58, 29)\n"
     ]
    }
   ],
   "source": [
    "def build_data_structures(length_input_dataset, max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens, num_decoder_tokens):\n",
    "    encoder_input_data = np.zeros((length_input_dataset, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "    decoder_input_data = np.zeros((length_input_dataset, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "    decoder_target_data = np.zeros((length_input_dataset, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "    print(\"Dimensionality of encoder input data is : \", encoder_input_data.shape)\n",
    "    print(\"Dimensionality of decoder input data is : \", decoder_input_data.shape)\n",
    "    print(\"Dimensionality of decoder target data is : \", decoder_target_data.shape)\n",
    "    \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
    "\n",
    "encoder_input_data, decoder_input_data, decoder_target_data = build_data_structures(len(input_dataset), \n",
    "                                                                                    max_encoder_seq_length, \n",
    "                                                                                    max_decoder_seq_length, \n",
    "                                                                                    num_encoder_tokens, \n",
    "                                                                                    num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data to the built data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_okGtmkIeGOC"
   },
   "outputs": [],
   "source": [
    "def add_data_to_data_structures(input_dataset, target_dataset, encoder_input_data, decoder_input_data, decoder_target_data):\n",
    "    for i, (input_data_point, target_data_point) in enumerate(zip(input_dataset, target_dataset)):\n",
    "        for t, char in enumerate(input_data_point):\n",
    "            encoder_input_data[i, t, input_char_to_idx[char]] = 1.\n",
    "        for t, char in enumerate(target_data_point):\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_input_data[i, t, target_char_to_idx[char]] = 1.\n",
    "            if t > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_target_data[i, t - 1, target_char_to_idx[char]] = 1.\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQcJamwaeGOH"
   },
   "outputs": [],
   "source": [
    "encoder_input_data, decoder_input_data, decoder_target_data = add_data_to_data_structures(input_dataset, \n",
    "                                                                                          target_dataset, \n",
    "                                                                                          encoder_input_data, \n",
    "                                                                                          decoder_input_data, \n",
    "                                                                                          decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwadHEJ1eGOM"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 100\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcXQZANneGOR"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VX_O_UzheGOX"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYIBY06AeGOb"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "              outputs=decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "sG8R3LhFeGOf",
    "outputId": "c990af8d-ccc3-4fe3-ff9a-048444b4efe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 27)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 29)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 290816      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  292864      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 29)     7453        lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 591,133\n",
      "Trainable params: 591,133\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3cLKLtZLeGOk",
    "outputId": "fd3e86fa-5487-42b7-a28d-96fb8f38aabe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112000 samples, validate on 28000 samples\n",
      "Epoch 1/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.9022 - val_loss: 1.5125\n",
      "Epoch 2/100\n",
      "112000/112000 [==============================] - 115s 1ms/step - loss: 0.7103 - val_loss: 1.3070\n",
      "Epoch 3/100\n",
      "112000/112000 [==============================] - 115s 1ms/step - loss: 0.6220 - val_loss: 1.2398\n",
      "Epoch 4/100\n",
      "112000/112000 [==============================] - 116s 1ms/step - loss: 0.5705 - val_loss: 1.1785\n",
      "Epoch 5/100\n",
      "112000/112000 [==============================] - 116s 1ms/step - loss: 0.5368 - val_loss: 1.1203\n",
      "Epoch 6/100\n",
      "112000/112000 [==============================] - 116s 1ms/step - loss: 0.5117 - val_loss: 1.1075\n",
      "Epoch 7/100\n",
      "112000/112000 [==============================] - 115s 1ms/step - loss: 0.4921 - val_loss: 1.1037\n",
      "Epoch 8/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.4780 - val_loss: 1.0276\n",
      "Epoch 9/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.4666 - val_loss: 1.0442\n",
      "Epoch 10/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.4570 - val_loss: 1.0203\n",
      "Epoch 11/100\n",
      "112000/112000 [==============================] - 115s 1ms/step - loss: 0.4454 - val_loss: 1.0213\n",
      "Epoch 12/100\n",
      "112000/112000 [==============================] - 115s 1ms/step - loss: 0.4288 - val_loss: 1.0343\n",
      "Epoch 13/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.4176 - val_loss: 0.9991\n",
      "Epoch 14/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.4089 - val_loss: 1.0165\n",
      "Epoch 15/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.4017 - val_loss: 0.9997\n",
      "Epoch 16/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3957 - val_loss: 1.0365\n",
      "Epoch 17/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3901 - val_loss: 1.0217\n",
      "Epoch 18/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3849 - val_loss: 1.0044\n",
      "Epoch 19/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3798 - val_loss: 1.0305\n",
      "Epoch 20/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3767 - val_loss: 1.0021\n",
      "Epoch 21/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3734 - val_loss: 1.0155\n",
      "Epoch 22/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3672 - val_loss: 1.0603\n",
      "Epoch 23/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3630 - val_loss: 1.0339\n",
      "Epoch 24/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3589 - val_loss: 1.0530\n",
      "Epoch 25/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3553 - val_loss: 1.0389\n",
      "Epoch 26/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3516 - val_loss: 1.0156\n",
      "Epoch 27/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3482 - val_loss: 1.0313\n",
      "Epoch 28/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3450 - val_loss: 1.0497\n",
      "Epoch 29/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3420 - val_loss: 1.0442\n",
      "Epoch 30/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3391 - val_loss: 1.0422\n",
      "Epoch 31/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3364 - val_loss: 1.0891\n",
      "Epoch 32/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3339 - val_loss: 1.0797\n",
      "Epoch 33/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3313 - val_loss: 1.0783\n",
      "Epoch 34/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3289 - val_loss: 1.0818\n",
      "Epoch 35/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.3267 - val_loss: 1.0840\n",
      "Epoch 36/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3243 - val_loss: 1.0324\n",
      "Epoch 37/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3224 - val_loss: 1.0532\n",
      "Epoch 38/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3202 - val_loss: 1.1397\n",
      "Epoch 39/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3184 - val_loss: 1.1030\n",
      "Epoch 40/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3165 - val_loss: 1.1136\n",
      "Epoch 41/100\n",
      "112000/112000 [==============================] - 115s 1ms/step - loss: 0.3147 - val_loss: 1.1142\n",
      "Epoch 42/100\n",
      "112000/112000 [==============================] - 115s 1ms/step - loss: 0.3129 - val_loss: 1.0799\n",
      "Epoch 43/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.3112 - val_loss: 1.1010\n",
      "Epoch 44/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.3097 - val_loss: 1.1357\n",
      "Epoch 45/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.3080 - val_loss: 1.1242\n",
      "Epoch 46/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3066 - val_loss: 1.0892\n",
      "Epoch 47/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3052 - val_loss: 1.1222\n",
      "Epoch 48/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.3037 - val_loss: 1.1149\n",
      "Epoch 49/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.3022 - val_loss: 1.1083\n",
      "Epoch 50/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.3009 - val_loss: 1.1412\n",
      "Epoch 51/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2996 - val_loss: 1.1171\n",
      "Epoch 52/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2984 - val_loss: 1.1333\n",
      "Epoch 53/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2972 - val_loss: 1.1429\n",
      "Epoch 54/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2960 - val_loss: 1.1523\n",
      "Epoch 55/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2948 - val_loss: 1.1353\n",
      "Epoch 56/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2937 - val_loss: 1.1435\n",
      "Epoch 57/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2926 - val_loss: 1.1512\n",
      "Epoch 58/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2914 - val_loss: 1.1161\n",
      "Epoch 59/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2904 - val_loss: 1.1785\n",
      "Epoch 60/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2894 - val_loss: 1.1794\n",
      "Epoch 61/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2884 - val_loss: 1.1590\n",
      "Epoch 62/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2874 - val_loss: 1.1613\n",
      "Epoch 63/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2864 - val_loss: 1.2048\n",
      "Epoch 64/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2855 - val_loss: 1.1406\n",
      "Epoch 65/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2847 - val_loss: 1.1375\n",
      "Epoch 66/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2837 - val_loss: 1.2134\n",
      "Epoch 67/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2829 - val_loss: 1.1748\n",
      "Epoch 68/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2820 - val_loss: 1.1602\n",
      "Epoch 69/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2813 - val_loss: 1.1805\n",
      "Epoch 70/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2805 - val_loss: 1.1863\n",
      "Epoch 71/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2796 - val_loss: 1.1908\n",
      "Epoch 72/100\n",
      "112000/112000 [==============================] - 115s 1ms/step - loss: 0.2789 - val_loss: 1.1891\n",
      "Epoch 73/100\n",
      "112000/112000 [==============================] - 116s 1ms/step - loss: 0.2781 - val_loss: 1.2016\n",
      "Epoch 74/100\n",
      "112000/112000 [==============================] - 116s 1ms/step - loss: 0.2774 - val_loss: 1.1849\n",
      "Epoch 75/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2766 - val_loss: 1.1953\n",
      "Epoch 76/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2759 - val_loss: 1.2224\n",
      "Epoch 77/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2752 - val_loss: 1.2196\n",
      "Epoch 78/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2744 - val_loss: 1.1878\n",
      "Epoch 79/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2737 - val_loss: 1.2298\n",
      "Epoch 80/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2731 - val_loss: 1.1755\n",
      "Epoch 81/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2724 - val_loss: 1.1913\n",
      "Epoch 82/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2719 - val_loss: 1.2166\n",
      "Epoch 83/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2711 - val_loss: 1.2252\n",
      "Epoch 84/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2705 - val_loss: 1.2172\n",
      "Epoch 85/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2699 - val_loss: 1.2170\n",
      "Epoch 86/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2693 - val_loss: 1.2278\n",
      "Epoch 87/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2686 - val_loss: 1.2008\n",
      "Epoch 88/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2681 - val_loss: 1.1933\n",
      "Epoch 89/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2675 - val_loss: 1.2348\n",
      "Epoch 90/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2670 - val_loss: 1.1955\n",
      "Epoch 91/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2664 - val_loss: 1.2013\n",
      "Epoch 92/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2658 - val_loss: 1.2126\n",
      "Epoch 93/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2654 - val_loss: 1.2629\n",
      "Epoch 94/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2648 - val_loss: 1.2034\n",
      "Epoch 95/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2644 - val_loss: 1.2245\n",
      "Epoch 96/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2638 - val_loss: 1.2558\n",
      "Epoch 97/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2633 - val_loss: 1.2445\n",
      "Epoch 98/100\n",
      "112000/112000 [==============================] - 114s 1ms/step - loss: 0.2628 - val_loss: 1.2249\n",
      "Epoch 99/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2623 - val_loss: 1.2805\n",
      "Epoch 100/100\n",
      "112000/112000 [==============================] - 113s 1ms/step - loss: 0.2618 - val_loss: 1.2251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f7fcec7d1d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wY80ZCIseGOo"
   },
   "outputs": [],
   "source": [
    "model.save('Output Files/neural_machine_translation_french_to_english.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our model for inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kW9tivC9eGOt"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9_DZBhyeGOx"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_char_to_idx['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "    \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = target_idx_to_char[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "              stop_condition = True\n",
    "      \n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "    \n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's translate some French sentences to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7QnRlMHeGO1"
   },
   "outputs": [],
   "source": [
    "def decode(seq_index):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_dataset[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "1IbAcQuDeGO5",
    "outputId": "a60126ac-f6dd-4fa6-95e7-6cfb058f172e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: hier etait une bonne journee\n",
      "Decoded sentence: yesterday was a little too far\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decode(55000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ng_3YpbWXiZi",
    "outputId": "4acf6eb7-5a7c-4d2f-c0be-1d7cec7ba050"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: jen ai ras le bol\n",
      "Decoded sentence: im still not sure\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decode(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "3Vh-z5N1ZOEM",
    "outputId": "c64a0d2d-39f8-4a2c-d99d-48200e57d1ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: soyez calmes\n",
      "Decoded sentence: be careful\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decode(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "P-VmNnYMZUMs",
    "outputId": "8bfc8543-cb20-4b22-8122-44c90c10f88a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: je me sens affreusement mal\n",
      "Decoded sentence: i feel like such an idiot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decode(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "jo6-UTwnaEiU",
    "outputId": "19d48d04-f570-4d07-f153-1510bd1e16b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: je pense que je peux arranger ca\n",
      "Decoded sentence: i think i can do it\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decode(40884)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of French_To_English2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
