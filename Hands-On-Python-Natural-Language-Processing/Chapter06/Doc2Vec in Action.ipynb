{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building paragraph vectors using Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import common text corpus, Doc2Vec algorithm and Tagged Document functionality from Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus on which training will happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Tagged Documents from the corpus as that's an expectation from the Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['human', 'interface', 'computer'], tags=[0]),\n",
       " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=[1]),\n",
       " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=[2]),\n",
       " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=[3]),\n",
       " TaggedDocument(words=['user', 'response', 'time'], tags=[4]),\n",
       " TaggedDocument(words=['trees'], tags=[5]),\n",
       " TaggedDocument(words=['graph', 'trees'], tags=[6]),\n",
       " TaggedDocument(words=['graph', 'minors', 'trees'], tags=[7]),\n",
       " TaggedDocument(words=['graph', 'minors', 'survey'], tags=[8])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a basic Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=5, min_count=1, workers=4, epochs = 40)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the vector size (should be 5 as we specified it on top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many document vectors did we train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.docvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the vocabulary information for the model we built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': <gensim.models.keyedvectors.Vocab at 0x1275bfa58>,\n",
       " 'interface': <gensim.models.keyedvectors.Vocab at 0x1275bfa90>,\n",
       " 'computer': <gensim.models.keyedvectors.Vocab at 0x1275bfac8>,\n",
       " 'survey': <gensim.models.keyedvectors.Vocab at 0x1275bfb00>,\n",
       " 'user': <gensim.models.keyedvectors.Vocab at 0x1275bfb38>,\n",
       " 'system': <gensim.models.keyedvectors.Vocab at 0x1275bfb70>,\n",
       " 'response': <gensim.models.keyedvectors.Vocab at 0x1275bfba8>,\n",
       " 'time': <gensim.models.keyedvectors.Vocab at 0x1275bfbe0>,\n",
       " 'eps': <gensim.models.keyedvectors.Vocab at 0x1275bfc18>,\n",
       " 'trees': <gensim.models.keyedvectors.Vocab at 0x1275bfc50>,\n",
       " 'graph': <gensim.models.keyedvectors.Vocab at 0x1275bfc88>,\n",
       " 'minors': <gensim.models.keyedvectors.Vocab at 0x1275bfcc0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's infer a vector based on the trained Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00837848  0.02508169 -0.07431821 -0.0596405  -0.0423368 ]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a new model changing vector size and minimum count eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=3, epochs=40)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': <gensim.models.keyedvectors.Vocab at 0x1275e5278>,\n",
       " 'system': <gensim.models.keyedvectors.Vocab at 0x1275e52b0>,\n",
       " 'trees': <gensim.models.keyedvectors.Vocab at 0x1275e52e8>,\n",
       " 'graph': <gensim.models.keyedvectors.Vocab at 0x1275e5320>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0007554   0.00245294 -0.00753151 -0.00607859 -0.00448105  0.00735318\n",
      " -0.00594467  0.00859313  0.00224831  0.00329965 -0.00813412 -0.00946166\n",
      " -0.00889105 -0.00073677  0.00183127  0.00870271  0.00402407 -0.00895064\n",
      " -0.00469407 -0.00866868  0.00176067 -0.00080887 -0.00720792  0.0097493\n",
      "  0.00787539  0.00132159  0.00142888  0.00662106  0.00739355 -0.0035373\n",
      " -0.004258    0.00317122 -0.00414719  0.0087981   0.00254999  0.0062838\n",
      "  0.00276298 -0.00396981  0.00029113  0.0015878   0.0088333   0.00634579\n",
      " -0.00670296  0.00886645 -0.00246914 -0.00679858 -0.0062902   0.00156767\n",
      "  0.00728981  0.00063676]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec built next would be based on the distributed memory model (dm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, dm=1)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00083785  0.0025081  -0.00743164 -0.0059641  -0.00423381  0.00731251\n",
      " -0.00578678  0.00872545  0.00228341  0.0034173  -0.00808397 -0.00950016\n",
      " -0.00906238 -0.00080767  0.00171906  0.00896924  0.0040419  -0.00885137\n",
      " -0.00471259 -0.00870188  0.00178028 -0.00072872 -0.00730505  0.0096972\n",
      "  0.00783329  0.0013391   0.00138172  0.00646492  0.00736424 -0.0035704\n",
      " -0.0042251   0.00305551 -0.0041782   0.00852095  0.00254887  0.00603066\n",
      "  0.00278338 -0.00383981  0.00029436  0.00147101  0.00855696  0.00640369\n",
      " -0.00688233  0.00874824 -0.0024071  -0.00703622 -0.00629042  0.00137818\n",
      "  0.00750697  0.00077192]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec built next would be based on the distributed bag of words approach (dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, dm=0)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00109621  0.00272048 -0.00708021 -0.0056539  -0.0035218   0.0072564\n",
      " -0.00523689  0.00893386  0.00242381  0.00372012 -0.00790817 -0.00953043\n",
      " -0.00963668 -0.0006919   0.0014357   0.00975151  0.00398858 -0.00863759\n",
      " -0.00485293 -0.00876931  0.00181497 -0.00070308 -0.00734465  0.00965797\n",
      "  0.00781335  0.00126422  0.00142577  0.00607191  0.00750605 -0.00359481\n",
      " -0.0043268   0.00247477 -0.0040486   0.00760716  0.00243003  0.00547929\n",
      "  0.00270485 -0.00383133  0.00021018  0.00096664  0.00777186  0.00659784\n",
      " -0.00745498  0.0084297  -0.00252952 -0.0078846  -0.00605868  0.00084422\n",
      "  0.00801426  0.00132708]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the window size which controls the maximum distance between current and predicted word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=0)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00109621  0.00272048 -0.00708021 -0.0056539  -0.0035218   0.0072564\n",
      " -0.00523689  0.00893386  0.00242381  0.00372012 -0.00790817 -0.00953043\n",
      " -0.00963668 -0.0006919   0.0014357   0.00975151  0.00398858 -0.00863759\n",
      " -0.00485293 -0.00876931  0.00181497 -0.00070308 -0.00734465  0.00965797\n",
      "  0.00781335  0.00126422  0.00142577  0.00607191  0.00750605 -0.00359481\n",
      " -0.0043268   0.00247477 -0.0040486   0.00760716  0.00243003  0.00547929\n",
      "  0.00270485 -0.00383133  0.00021018  0.00096664  0.00777186  0.00659784\n",
      " -0.00745498  0.0084297  -0.00252952 -0.0078846  -0.00605868  0.00084422\n",
      "  0.00801426  0.00132708]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding initial learning rate and to what value should the learning rate drop to linearly over training (alpha and min_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01313599  0.09021752  0.15693103  0.05491399  0.221802   -0.03609728\n",
      "  0.20403768  0.16093309  0.02980033  0.12525356  0.11866798 -0.15696132\n",
      " -0.23446515  0.00503503 -0.06593265  0.41700405 -0.04970177  0.1680097\n",
      " -0.07858688 -0.15251276  0.1498729   0.04965634 -0.12973404 -0.0875756\n",
      " -0.16183794  0.022648   -0.02519816 -0.29822692 -0.00981279 -0.07755509\n",
      "  0.05255692 -0.22204016  0.00214513 -0.3955719  -0.04027079 -0.31845158\n",
      "  0.08010257  0.18387455 -0.0829942  -0.1848516  -0.3851935   0.09401936\n",
      " -0.2615898  -0.15556695 -0.08353131 -0.4627164   0.15202288 -0.16089936\n",
      "  0.2919812   0.28519666]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the dm_concat parameter to use concatenation of the word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, alpha=0.3, min_alpha=0.05, dm_concat=1)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13415436  0.0303736   0.09611408  0.1395972   0.16386569  0.0036322\n",
      "  0.02273775  0.03766986  0.09420739 -0.06807812  0.06191105  0.06978849\n",
      " -0.21992323  0.09518417 -0.03310432  0.09965468 -0.14452797 -0.02993996\n",
      " -0.1224978   0.07653727 -0.05898055 -0.07362843  0.12026148  0.07333527\n",
      "  0.09661347 -0.02674908  0.08087287 -0.00112457  0.13201286 -0.0426542\n",
      " -0.07348074 -0.12955241  0.06249566 -0.15799135  0.03026742 -0.08554384\n",
      " -0.15377186 -0.11494051  0.0040474  -0.20266768 -0.12127133 -0.01644059\n",
      " -0.1263317  -0.02892478 -0.09751968 -0.09645914 -0.04171879 -0.15448399\n",
      "  0.01604939  0.14704153]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the dm_mean parameter to use sum of the context word vectors (dm_mean=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, dm_concat=0, dm_mean=1, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01313599  0.09021752  0.15693103  0.05491399  0.221802   -0.03609728\n",
      "  0.20403768  0.16093309  0.02980033  0.12525356  0.11866798 -0.15696132\n",
      " -0.23446515  0.00503503 -0.06593265  0.41700405 -0.04970177  0.1680097\n",
      " -0.07858688 -0.15251276  0.1498729   0.04965634 -0.12973404 -0.0875756\n",
      " -0.16183794  0.022648   -0.02519816 -0.29822692 -0.00981279 -0.07755509\n",
      "  0.05255692 -0.22204016  0.00214513 -0.3955719  -0.04027079 -0.31845158\n",
      "  0.08010257  0.18387455 -0.0829942  -0.1848516  -0.3851935   0.09401936\n",
      " -0.2615898  -0.15556695 -0.08353131 -0.4627164   0.15202288 -0.16089936\n",
      "  0.2919812   0.28519666]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the dm_mean parameter to use mean of the context word vectors (dm_mean=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, dm_concat=0, dm_mean=0, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00935517  0.07616115  0.15255241  0.07638344  0.19263287 -0.07350364\n",
      "  0.12785366  0.1599799   0.05694617  0.05823422  0.11637199 -0.13700622\n",
      " -0.21772763 -0.04220163 -0.05569859  0.33506608 -0.05622197  0.15202586\n",
      " -0.07169427 -0.13657248  0.09855878  0.04425482 -0.11928431 -0.07140089\n",
      " -0.1587654   0.02786045 -0.0144077  -0.24685931 -0.02178081 -0.09650747\n",
      "  0.09494477 -0.17756443 -0.04105909 -0.33828962  0.02560137 -0.30136058\n",
      "  0.03067344  0.22339565 -0.09908482 -0.17326605 -0.32754987  0.05140997\n",
      " -0.21660927 -0.11799925 -0.09635676 -0.35610995  0.10597971 -0.12119675\n",
      "  0.23354535  0.21604767]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
